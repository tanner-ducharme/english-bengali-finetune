{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1c5fe0b9af0e43858b57648b7cf96295":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bdfaa5dad6e3449099024e5554ef0edb","IPY_MODEL_dd6606e5bb544126b2b742c9090b18aa","IPY_MODEL_49f1729b199d46d7bf4f5f618399d8f3"],"layout":"IPY_MODEL_985b962648514e44a4a9f24015fa35f4"}},"bdfaa5dad6e3449099024e5554ef0edb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_581d5191d5e74a7f8c94b03aea2ebe94","placeholder":"​","style":"IPY_MODEL_b8b7aba7e11c4c52974d312ebf919755","value":"Map: 100%"}},"dd6606e5bb544126b2b742c9090b18aa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_378d568e214c403b89f5b8626ad133e8","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_76b0dcd66ffa48caaa4fa09003d43e1e","value":100000}},"49f1729b199d46d7bf4f5f618399d8f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb3b931860dd4eab9e9cd0bedad378ce","placeholder":"​","style":"IPY_MODEL_3dac68653c7f4baeabb7a9a1d674082b","value":" 100000/100000 [00:06&lt;00:00, 18713.46 examples/s]"}},"985b962648514e44a4a9f24015fa35f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"581d5191d5e74a7f8c94b03aea2ebe94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8b7aba7e11c4c52974d312ebf919755":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"378d568e214c403b89f5b8626ad133e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76b0dcd66ffa48caaa4fa09003d43e1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb3b931860dd4eab9e9cd0bedad378ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dac68653c7f4baeabb7a9a1d674082b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a502e8a5eac94fcf959002c07fa6aaeb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6be3e115398448ebb49434756f59d42","IPY_MODEL_229d70adc69f47ffb8ee63c51ce923e6","IPY_MODEL_ae15180b7c1843b0b958759578955a49"],"layout":"IPY_MODEL_b0c4a533385f49bdb159e2179fead390"}},"d6be3e115398448ebb49434756f59d42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83ee3333392942fa8875041c0d26f474","placeholder":"​","style":"IPY_MODEL_e1c88a45c4f04b42a25a5fb3a8d75432","value":"Map: 100%"}},"229d70adc69f47ffb8ee63c51ce923e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3aaf0d3efce74c03bdde5c57f2796bca","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b3a74fd26ad48deaacf9efb0250cb84","value":500}},"ae15180b7c1843b0b958759578955a49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a80cf864ed454c80992b9435937fb3b9","placeholder":"​","style":"IPY_MODEL_5ab0d3cc6ba943f685f95a0af5dd3417","value":" 500/500 [00:00&lt;00:00, 9248.82 examples/s]"}},"b0c4a533385f49bdb159e2179fead390":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83ee3333392942fa8875041c0d26f474":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1c88a45c4f04b42a25a5fb3a8d75432":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3aaf0d3efce74c03bdde5c57f2796bca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b3a74fd26ad48deaacf9efb0250cb84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a80cf864ed454c80992b9435937fb3b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ab0d3cc6ba943f685f95a0af5dd3417":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/ift6289-project/\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8VQOKNG-EyT","executionInfo":{"status":"ok","timestamp":1714114140537,"user_tz":240,"elapsed":19660,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"258848c2-e200-4fcd-e329-29e8ca62f48f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ift6289-project\n","'Copy of ift6289-project-facebook mbart-large-50-many-to-many-mmt-BNtoEN.ipynb'\n","'Copy of ift6289-project-mt5-base-ENtoBN.ipynb'\n"," gemma_7b_finetune_template.ipynb\n"," hasan-etal-2020-low\n"," hasan-etal-2020-low.tar.bz2\n","'ift6289-project-facebook mbart-large-50-many-to-many-mmt-BNtoEN.ipynb'\n","'ift6289-project-facebook mbart-large-50-many-to-many-mmt-ENtoBN.ipynb'\n","'ift6289-project-facebook nllb-200-distilled-600M.ipynb'\n","'ift6289-project-Helsinki-NLP opus-mt-bn-en.ipynb'\n","'ift6289-project-Helsinki-NLP opus-mt-en-mul.ipynb'\n","'ift6289-project-Helsinki-NLP opus-mt-mul-en.ipynb'\n","'ift6289-project-meta-llama Llama-2-7b-hf.ipynb'\n"," ift6289-project-mt5-base-BNtoEN.ipynb\n"," ift6289-project-mt5-base-ENtoBN.ipynb\n"," ift6289-project-umt5-base-BNtoEN.ipynb\n"," ift6289-project-umt5-base-ENtoBN.ipynb\n"," logs\n"," results\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Ja0sdikFFS3X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714114230867,"user_tz":240,"elapsed":90333,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"f607cd83-bb8f-4631-9066-757baf567a62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets)\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.3)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n","Collecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, portalocker, dill, colorama, sacrebleu, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed colorama-0.4.6 datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 portalocker-2.8.2 sacrebleu-2.4.2 xxhash-3.4.1\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Collecting ml_things\n","  Downloading ml_things-0.0.1.tar.gz (8.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ml_things) (1.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ml_things) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ml_things) (2.31.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from ml_things) (4.66.2)\n","Collecting ftfy>=5.8 (from ml_things)\n","  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from ml_things) (3.7.1)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=5.8->ml_things) (0.2.13)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ml_things) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ml_things) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ml_things) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ml_things) (2024.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ml_things) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ml_things) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ml_things) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->ml_things) (1.16.0)\n","Building wheels for collected packages: ml_things\n","  Building wheel for ml_things (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ml_things: filename=ml_things-0.0.1-py3-none-any.whl size=24393 sha256=002781ba230d37fa024ada581eee0dc9fbec8cdd0dbd576074bb0d0c12649d84\n","  Stored in directory: /root/.cache/pip/wheels/2a/b9/36/3725744c1d8ebec00cd847c9461b4352ce08de9d3f20b6bdcf\n","Successfully built ml_things\n","Installing collected packages: ftfy, ml_things\n","Successfully installed ftfy-6.2.0 ml_things-0.0.1\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Collecting transformers[torch]\n","  Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate\n","  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->transformers[torch])\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, accelerate\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.40.0\n","    Uninstalling transformers-4.40.0:\n","      Successfully uninstalled transformers-4.40.0\n","Successfully installed accelerate-0.29.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 transformers-4.40.1\n"]}],"source":["!pip install datasets transformers[sentencepiece] sacrebleu\n","!pip install transformers\n","!pip install ml_things\n","!pip install transformers[torch] accelerate -U"]},{"cell_type":"code","source":["from transformers import set_seed, AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, pipeline, MBartForConditionalGeneration, MBart50TokenizerFast\n","from datasets import Dataset, load_dataset, load_metric\n","import torch\n","import pandas as pd\n","from tqdm.auto import tqdm  # tqdm is great for progress bars\n","import sacrebleu\n","import numpy as np"],"metadata":{"id":"cwpjGrCEreJj","executionInfo":{"status":"ok","timestamp":1714114240722,"user_tz":240,"elapsed":9858,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["set_seed(42)\n","\n","dataset = load_dataset(\"csebuetnlp/BanglaNMT\")\n","# print(dataset)\n","# print(dataset['train'][0])\n","# print(dataset['train'][1])\n","# print(dataset['train'][2])\n","# print(dataset['train'][0]['bn'])\n","# print(dataset['train'][0]['en'])\n","\n","training_subset_size = 100000\n","dataset[\"train\"] = dataset[\"train\"].select(range(training_subset_size))"],"metadata":{"id":"ntmlpv1Gt7ED","executionInfo":{"status":"ok","timestamp":1714115369391,"user_tz":240,"elapsed":1847,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Specify the model checkpoint\n","# model_checkpoint = \"facebook/nllb-200-distilled-600M\"\n","model_checkpoint = \"facebook/mbart-large-50-many-to-many-mmt\"\n","# model_checkpoint = \"t5-base\"\n","tokenizer = MBart50TokenizerFast.from_pretrained(model_checkpoint)"],"metadata":{"id":"mAINn-p5sAn2","executionInfo":{"status":"ok","timestamp":1714115371565,"user_tz":240,"elapsed":2176,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def preprocess_function(examples):\n","    inputs = [ex for ex in examples['en']]\n","    targets = [ex for ex in examples['bn']]\n","    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(targets, max_length=128, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenizer.src_lang = \"en_XX\"\n","tokenizer.tgt_lang = \"bn_IN\"\n","tokenized_datasets = dataset.map(preprocess_function, batched=True)\n","print(tokenized_datasets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299,"referenced_widgets":["1c5fe0b9af0e43858b57648b7cf96295","bdfaa5dad6e3449099024e5554ef0edb","dd6606e5bb544126b2b742c9090b18aa","49f1729b199d46d7bf4f5f618399d8f3","985b962648514e44a4a9f24015fa35f4","581d5191d5e74a7f8c94b03aea2ebe94","b8b7aba7e11c4c52974d312ebf919755","378d568e214c403b89f5b8626ad133e8","76b0dcd66ffa48caaa4fa09003d43e1e","bb3b931860dd4eab9e9cd0bedad378ce","3dac68653c7f4baeabb7a9a1d674082b"]},"id":"WX_0b33nspN_","executionInfo":{"status":"ok","timestamp":1714115377885,"user_tz":240,"elapsed":6328,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"c5e3a819-4d80-447a-b99a-692ae14ecab4"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c5fe0b9af0e43858b57648b7cf96295"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['bn', 'en', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 100000\n","    })\n","    test: Dataset({\n","        features: ['bn', 'en', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 1000\n","    })\n","    validation: Dataset({\n","        features: ['bn', 'en', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 597\n","    })\n","})\n"]}]},{"cell_type":"code","source":["for i in range(3):  # Adjust the range as needed\n","    print(f\"\\nExample {i+1}:\")\n","    print(\"Input (English):\", tokenizer.decode(tokenized_datasets['train'][i]['input_ids'], skip_special_tokens=True))\n","    print(\"Label (Bengali):\", tokenizer.decode(tokenized_datasets['train'][i]['labels'], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKwj7kiKA6zI","executionInfo":{"status":"ok","timestamp":1714115377885,"user_tz":240,"elapsed":18,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"ed5a2ced-5b6d-485d-eb33-3c4076f0506f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Example 1:\n","Input (English): Just keep me informed.\n","Label (Bengali): আমাকে সব কিছু জানাও\n","\n","Example 2:\n","Input (English): It's bad, \"Amor and Psyche\" is, master.\n","Label (Bengali): \"এ্যামোর এন্ড সাইকি\", এটা খারাপ, মনিব এটায় প্রচুর পরিমাণে চিরহরিৎ (একপ্রকার সুগন্ধী লতা) আছে আর প্রচুর পরিমাণে...\n","\n","Example 3:\n","Input (English): Overtake\n","Label (Bengali): কাছানো\n"]}]},{"cell_type":"code","source":["model = MBartForConditionalGeneration.from_pretrained(model_checkpoint)\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"id":"fbwOAeqityRj","executionInfo":{"status":"ok","timestamp":1714115382780,"user_tz":240,"elapsed":4912,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Load both BLEU and SacreBLEU metrics\n","bleu_metric = load_metric('bleu')\n","sacrebleu_metric = load_metric('sacrebleu')\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","\n","    # In case the model returns more than the prediction logits\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds = [pred.strip() for pred in decoded_preds]\n","    decoded_labels = [[label.strip()] for label in decoded_labels]\n","\n","    # # Compute BLEU score\n","    # bleu_result = bleu_metric.compute(predictions=decoded_preds, references=[decoded_labels])\n","    # Compute SacreBLEU score\n","    sacrebleu_result = sacrebleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n","\n","    # Prepare result dictionary\n","    results = {\n","        # \"bleu\": bleu_result['score'],\n","        \"sacrebleu\": sacrebleu_result['score']\n","    }\n","\n","    return results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWNAvwuRyTbr","executionInfo":{"status":"ok","timestamp":1714115384083,"user_tz":240,"elapsed":1306,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"f7e4ce7d-feed-4b62-8108-c42bf388ef8d"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/bleu/bleu.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/sacrebleu/sacrebleu.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import logging\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","# Define the training arguments\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=3,\n","    predict_with_generate=True,\n","    logging_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"sacrebleu\",\n","    # report_to=\"none\",\n",")\n","\n","# Initialize the trainer\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","# # Pre-training test results\n","baseline_test_results = trainer.predict(tokenized_datasets[\"test\"], metric_key_prefix=\"test\")\n","print(\"Baseline Test Metrics:\", baseline_test_results.metrics)\n","baseline_validation_results = trainer.evaluate()\n","print(\"Baseline Validation Metrics:\", baseline_validation_results)\n","\n","# Fine-tune the model\n","print(\"\\nFine-tuning the model...\")\n","trainer.train()\n","print(\"Model fine-tuning complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"JJ5oneuGu6EL","outputId":"9d305adc-c3c5-453b-958a-60757a26d0b0","executionInfo":{"status":"ok","timestamp":1714127166284,"user_tz":240,"elapsed":6940198,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}}},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Baseline Test Metrics: {'test_loss': 1.6124364137649536, 'test_sacrebleu': 16.420569390024426, 'test_runtime': 90.2793, 'test_samples_per_second': 11.077, 'test_steps_per_second': 0.698}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='76' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [38/38 37:59]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Baseline Validation Metrics: {'eval_loss': 1.6206969022750854, 'eval_sacrebleu': 16.962782455899184, 'eval_runtime': 55.3768, 'eval_samples_per_second': 10.781, 'eval_steps_per_second': 0.686}\n","\n","Fine-tuning the model...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='18750' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [18750/18750 1:53:13, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Sacrebleu</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.504700</td>\n","      <td>1.508793</td>\n","      <td>17.409048</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.241400</td>\n","      <td>1.450287</td>\n","      <td>19.208984</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.151800</td>\n","      <td>1.439144</td>\n","      <td>19.542106</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5, 'forced_eos_token_id': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5, 'forced_eos_token_id': 2}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"]},{"output_type":"stream","name":"stdout","text":["Model fine-tuning complete.\n"]}]},{"cell_type":"code","source":["# Evaluate the model\n","validation_results = trainer.evaluate()\n","print(\"Final validation Metrics\", validation_results)"],"metadata":{"id":"0R5hFMTY-1uR","colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"status":"ok","timestamp":1714127223940,"user_tz":240,"elapsed":57671,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"34b6cdd9-812e-4053-ace7-d28292e95e9e"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [38/38 00:56]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Final validation Metrics {'eval_loss': 1.4391437768936157, 'eval_sacrebleu': 19.542105744215593, 'eval_runtime': 57.9247, 'eval_samples_per_second': 10.306, 'eval_steps_per_second': 0.656, 'epoch': 3.0}\n"]}]},{"cell_type":"code","source":["# Calculate scores on the test set\n","final_test_results = trainer.predict(tokenized_datasets[\"test\"], metric_key_prefix=\"test\")\n","print(\"Final Test Metrics:\", final_test_results.metrics)"],"metadata":{"id":"As5H8iltxwlL","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1714127312934,"user_tz":240,"elapsed":89011,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"e0d9f2c2-f90c-41e6-9d51-4a5edc8edc1c"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Final Test Metrics: {'test_loss': 1.4336414337158203, 'test_sacrebleu': 18.921369295393067, 'test_runtime': 89.0011, 'test_samples_per_second': 11.236, 'test_steps_per_second': 0.708}\n"]}]},{"cell_type":"code","source":["# Decode the predictions and labels\n","decoded_predictions = tokenizer.batch_decode(final_test_results.predictions, skip_special_tokens=True)\n","# decoded_labels = tokenizer.batch_decode(final_test_results.label_ids, skip_special_tokens=True)\n","labels = np.where(final_test_results.label_ids != -100, final_test_results.label_ids, tokenizer.pad_token_id)\n","decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","# Print a sample of the predictions and labels\n","print(\"Sample Predictions and Labels:\")\n","for i in range(10):  # Adjust the range to print more or fewer examples\n","    print(f\"\\nPrediction {i+1}: {decoded_predictions[i]}\")\n","    print(f\"Label {i+1}: {decoded_labels[i]}\")"],"metadata":{"id":"mn3YMpvCPE5g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714127313147,"user_tz":240,"elapsed":229,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"9cffb7c1-244a-488a-80d8-5fbbbe6e3896"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample Predictions and Labels:\n","\n","Prediction 1: যুক্তরাজ্যের বাংলাদেশ হাই কমিশনার সাইদা মুনা তাসনেন এবং লন্ডনে বাংলাদেশ মিশনের সিনিয়র কর্মকর্তারা তাকে বিমানবন্দরে দেখা করেন।\n","Label 1: বিমানবন্দরে যুক্তরাজ্যে নিযুক্ত বাংলাদেশ হাইকমিশনার সাঈদা মুনা তাসনীম ও লন্ডনে বাংলাদেশ মিশনের জ্যেষ্ঠ কর্মকর্তারা তাকে বিদায় জানান।\n","\n","Prediction 2: এই সন্ত্রাসীদের কোনো জাতি, ধর্ম আর দেশ নেই।\n","Label 2: সন্ত্রাসীদের কোনো বর্ণ, ধর্ম ও দেশ নেই।\n","\n","Prediction 3: কর্নেল বিশ্ববিদ্যালয়ের অধ্যাপক ডেরেক কেবেরা একটি প্রবন্ধ লিখেছিলেন যার নাম ছিল, \"বিষম চিন্তার অন্ধকার দিক।\"\n","Label 3: কর্নেল বিশ্ববিদ্যালয়ের অধ্যাপক ডেরেক কাবেরা \"শ্রেণিবদ্ধ চিন্তার অন্ধকার দিক\" নামের একটি প্রবন্ধ রচনা করেছেন।\n","\n","Prediction 4: তিনি বলেন যে জনগণ পিঁয়াজ ৪৫ কিলোগ্রামে, চিনি ৫০ কিলোগ্রামে, লণ্টিল ৫০ কিলোগ্রামে এবং সয়াজ তেল লিটারে ৮৫ টাকায় কিনতে পারে।\n","Label 4: জনসাধারণ প্রতি কেজি পেঁয়াজ ৪৫ টাকায়, চিনি ৫০ টাকায়, মশুর ডাল ৫০ টাকায় ও প্রতি লিটার সয়াবিন তেল ৮৫ টাকায় কিনতে পারবে বলে জানান তিনি।\n","\n","Prediction 5: স্থানীয়রা এবং শ্রীপুর ফায়ার স্টেশনের দুটি ইউনিটের ফৌজদাররা প্রায় দুই ঘন্টা ধরে আগুন নিয়ন্ত্রিত করে।\n","Label 5: শ্রীপুর ফায়ার স্টেশনের দুই ইউনিটের কর্মীরা প্রায় দুঘণ্টা চেষ্টা করে আগুন নেভায়।\n","\n","Prediction 6: প্রধানমন্ত্রী শেখ হাসিনা বৃহস্পতিবার সকালবেলা রোম থেকে আবুধাবিতে পৌঁছেছেন। তিনি ইতালি এবং ভ্যাটিকান সিটিতে তার চারদিনের সরকারি সফর শেষ করেছেন।\n","Label 6: প্রধানমন্ত্রী শেখ হাসিনা ইতালি এবং ভ্যাটিকান সিটিতে ৪ দিনের সরকারি সফর শেষে বৃহস্পতিবার সকালে রোম থেকে আবুধাবিতে পৌঁছেছেন।\n","\n","Prediction 7: ভারতের প্রধানমন্ত্রী নরেন্দ্র মোদি আশ্বাস দেন যে বাংলাদেশের দীর্ঘ সময় ধরে চলা রোহিঙ্গা সংকট সমাধানে নতুন দিল্লির সহযোগিতা চলতে থাকবে।\n","Label 7: ভারতের প্রধানমন্ত্রী নরেন্দ্র মোদি আশ্বস্ত করে বলেছেন, বাংলাদেশের রোহিঙ্গা সমস্যা নিরসনে নয়া দিল্লীর সহযোগিতা অব্যাহত থাকবে।\n","\n","Prediction 8: জাপান বাংলাদেশকে পুরোপুরি সমর্থন জানাচ্ছে হিংহাইয়াদের দেশত্যাগ বিষয়কে\n","Label 8: রোহিঙ্গা প্রত্যাবাসন ইস্যুতে বাংলাদেশকে জাপানের পূর্ণসমর্থন\n","\n","Prediction 9: সরওয়ার সাগর, মাসারাঙ্গা টেলিভিশনের সংবাদ সম্পাদক এবং তার স্ত্রী রুনি, এটিএন বাংলার সিনিয়র রিপোর্টারকে ১১ ফেব্রুয়ারী, ২০১২ তারিখে রাজধানীর পশ্চিম রাজাবাজারে তাদের ভাড়া করা একটি ফ্ল্যাটে নৃশংসভাবে হত্যা করা হয়।\n","Label 9: ২০১২ সালের ১১ ফেব্রুয়ারি রাতে রাজধানীর পশ্চিম রাজাবাজারে মাছরাঙা টেলিভিশনের বার্তা সম্পাদক সাগর সারওয়ার এবং এটিএন বাংলার জ্যেষ্ঠ প্রতিবেদক রুনি নিজ ভাড়া বাসায় নির্মমভাবে খুন হন।\n","\n","Prediction 10: তিনি বলেছিলেন, \"বাংলাদেশ ধর্ম ও সংগতির এক স্পষ্ট উদাহরণ।\"\n","Label 10: তিনি বলেছেন, 'বাংলাদেশ হলো আন্ত ধর্ম ও ঐকতানের প্রকৃষ্ট উদাহরণ।'\n"]}]},{"cell_type":"markdown","source":["# Test on SUPara-benchmark"],"metadata":{"id":"7uplZPkb-IDq"}},{"cell_type":"code","source":["supara_target_test_path = f\"hasan-etal-2020-low/data/SUPara-benchmark/suparatest2018/suparatest2018_bn.txt\"\n","supara_source_test_path = f\"hasan-etal-2020-low/data/SUPara-benchmark/suparatest2018/suparatest2018_en.txt\"\n","\n","with open(supara_source_test_path, \"r\", encoding=\"utf-8\") as f:\n","    supara_source_data = f.readlines()\n","\n","with open(supara_target_test_path, \"r\", encoding=\"utf-8\") as f:\n","    supara_target_data = f.readlines()\n","\n","print(supara_source_data[0])\n","print(supara_target_data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rE_Xxap-Mrz","executionInfo":{"status":"ok","timestamp":1714127313147,"user_tz":240,"elapsed":14,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"29058adb-301c-4d42-ad0a-1a21640c66f1"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["She likes red roses.\n","\n","সে লাল গোলাপ পছন্দ করে।\n","\n"]}]},{"cell_type":"code","source":["# def preprocess_function_supara(examples):\n","#     inputs = [\"Translate Bengali to English: \" + ex for ex in examples[\"bn\"]]\n","#     model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n","#     # Prepare the labels (English translations)\n","#     with tokenizer.as_target_tokenizer():\n","#         labels = tokenizer(examples['en'], max_length=128, truncation=True, padding=\"max_length\")\n","#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n","#     return model_inputs\n","\n","supara_dataset = Dataset.from_dict({\"en\": supara_source_data, \"bn\": supara_target_data})\n","tokenized_supara_dataset = supara_dataset.map(preprocess_function, batched=True)\n","print(tokenized_supara_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176,"referenced_widgets":["a502e8a5eac94fcf959002c07fa6aaeb","d6be3e115398448ebb49434756f59d42","229d70adc69f47ffb8ee63c51ce923e6","ae15180b7c1843b0b958759578955a49","b0c4a533385f49bdb159e2179fead390","83ee3333392942fa8875041c0d26f474","e1c88a45c4f04b42a25a5fb3a8d75432","3aaf0d3efce74c03bdde5c57f2796bca","7b3a74fd26ad48deaacf9efb0250cb84","a80cf864ed454c80992b9435937fb3b9","5ab0d3cc6ba943f685f95a0af5dd3417"]},"id":"ZlKBmKYB-RWy","executionInfo":{"status":"ok","timestamp":1714127313147,"user_tz":240,"elapsed":7,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"3efbc489-adac-4ab3-cebc-b557af15885d"},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a502e8a5eac94fcf959002c07fa6aaeb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['en', 'bn', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 500\n","})\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3921: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Perform inference with the fine-tuned model\n","final_test_results_supara = trainer.predict(tokenized_supara_dataset, metric_key_prefix=\"test\")\n","print(\"Final test metrics SUPara:\", final_test_results_supara.metrics)\n","print(\"Final test results SUPara:\", final_test_results_supara)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"I21r2Hue-VWq","executionInfo":{"status":"ok","timestamp":1714127352921,"user_tz":240,"elapsed":39778,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"c360dfcd-d135-401d-91d8-1277b44ff62b"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Final test metrics SUPara: {'test_loss': 1.4738273620605469, 'test_sacrebleu': 16.05880568179493, 'test_runtime': 39.7596, 'test_samples_per_second': 12.576, 'test_steps_per_second': 0.805}\n","Final test results SUPara: PredictionOutput(predictions=array([[     2, 250028,  22540, ...,      1,      1,      1],\n","       [     2, 250028,  72622, ...,      1,      1,      1],\n","       [     2, 250028,  35729, ...,      1,      1,      1],\n","       ...,\n","       [     2, 250028, 188027, ...,      1,      1,      1],\n","       [     2, 250028,  69151, ...,      1,      1,      1],\n","       [     2, 250028,  62444, ...,      1,      1,      1]]), label_ids=array([[250028,  22540,  50395, ...,      1,      1,      1],\n","       [250028,  10814,  29432, ...,      1,      1,      1],\n","       [250028,  35729, 131723, ...,      1,      1,      1],\n","       ...,\n","       [250028, 220219, 152596, ...,      1,      1,      1],\n","       [250028, 170394, 113341, ...,      1,      1,      1],\n","       [250028,  10066,  61232, ...,      1,      1,      1]]), metrics={'test_loss': 1.4738273620605469, 'test_sacrebleu': 16.05880568179493, 'test_runtime': 39.7596, 'test_samples_per_second': 12.576, 'test_steps_per_second': 0.805})\n"]}]},{"cell_type":"code","source":["# Decode the predicted sequences\n","decoded_predictions_supara = tokenizer.batch_decode(final_test_results_supara.predictions, skip_special_tokens=True)\n","labels_supara = np.where(final_test_results_supara.label_ids != -100, final_test_results_supara.label_ids, tokenizer.pad_token_id)\n","decoded_labels_supara = tokenizer.batch_decode(labels_supara, skip_special_tokens=True)\n","\n","# Print a sample of the predictions and labels\n","print(\"Sample Predictions and Labels:\")\n","for i in range(10):  # Adjust the range to print more or fewer examples\n","    print(f\"\\nPrediction {i+1}: {decoded_predictions_supara[i]}\")\n","    print(f\"Label {i+1}: {decoded_labels_supara[i]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1K7D-8S-cv4","executionInfo":{"status":"ok","timestamp":1714127352921,"user_tz":240,"elapsed":18,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"163c7f47-f6ff-4975-8087-f4c265133989"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample Predictions and Labels:\n","\n","Prediction 1: সে লাল গোলাপ পছন্দ করে।\n","Label 1: সে লাল গোলাপ পছন্দ করে।\n","\n","Prediction 2: এটি আমাদের দেহকে দৃঢ় করে তোলে।\n","Label 2: ইহা আমাদের শরীরকে দৃঢ় করে।\n","\n","Prediction 3: আমরা বাংলাদেশে থাকি।\n","Label 3: আমরা বাংলাদেশে বাস করি।\n","\n","Prediction 4: মানুষের জীবন খুবই ছোট।\n","Label 4: মানব জীবন অত্যন্ত সংক্ষিপ্ত।\n","\n","Prediction 5: ট্রাফিক পুলিশদের কঠোর দায়িত্ব রয়েছে।\n","Label 5: ট্রাফিক পুলিশের অনেক দায়িত্ব থাকে।\n","\n","Prediction 6: ক্রিকেট আমার প্রিয় খেলা।\n","Label 6: ক্রিকেট আমার প্রিয় খেলা।\n","\n","Prediction 7: জনসচেতনতা সৃষ্টি করা উচিত।\n","Label 7: গণসচেতনতা সৃষ্টি করা উচিত।\n","\n","Prediction 8: কিছু সমস্যা থাকতে পারে।\n","Label 8: সেখানে কিছু সমস্যা থাকতে পারে।\n","\n","Prediction 9: ওর নাম কি?\n","Label 9: তার নাম কি?\n","\n","Prediction 10: আমাদের কলেজ অনেক প্রাচীন।\n","Label 10: আমাদের কলেজ বহু প্রাচীন।\n"]}]}]}