{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":98638,"status":"ok","timestamp":1714264716134,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"},"user_tz":240},"id":"CteantQE0GNB","outputId":"365a3cc8-a841-4258-c02f-2d2ba9e5b6c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ift6289-project\n","'Copy of ift6289-project-facebook mbart-large-50-many-to-many-mmt-BNtoEN.ipynb'\n","'Copy of ift6289-project-mt5-base-ENtoBN.ipynb'\n"," gemma_7b_finetune_template.ipynb\n"," hasan-etal-2020-low\n"," hasan-etal-2020-low.tar.bz2\n","'ift6289-project-facebook mbart-large-50-many-to-many-mmt-BNtoEN.ipynb'\n","'ift6289-project-facebook mbart-large-50-many-to-many-mmt-ENtoBN.ipynb'\n","'ift6289-project-facebook nllb-200-distilled-600M.ipynb'\n","'ift6289-project-Helsinki-NLP opus-mt-bn-en.ipynb'\n","'ift6289-project-Helsinki-NLP opus-mt-en-mul.ipynb'\n","'ift6289-project-Helsinki-NLP opus-mt-mul-en.ipynb'\n","'ift6289-project-meta-llama Llama-2-7b-hf.ipynb'\n"," ift6289-project-mt5-base-BNtoEN.ipynb\n"," ift6289-project-mt5-base-ENtoBN.ipynb\n"," ift6289-project-umt5-base-BNtoEN.ipynb\n"," ift6289-project-umt5-base-ENtoBN.ipynb\n"," logs\n"," results\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/ift6289-project/\n","!ls"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88846,"status":"ok","timestamp":1714264804976,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"},"user_tz":240},"id":"Ja0sdikFFS3X","outputId":"ef22c032-7e0e-4f26-9568-9d7500d14d88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets)\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.3)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n","Collecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, portalocker, dill, colorama, sacrebleu, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed colorama-0.4.6 datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 portalocker-2.8.2 sacrebleu-2.4.2 xxhash-3.4.1\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Collecting ml_things\n","  Downloading ml_things-0.0.1.tar.gz (8.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ml_things) (1.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ml_things) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ml_things) (2.31.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from ml_things) (4.66.2)\n","Collecting ftfy>=5.8 (from ml_things)\n","  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from ml_things) (3.7.1)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=5.8->ml_things) (0.2.13)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->ml_things) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ml_things) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ml_things) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ml_things) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ml_things) (2024.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ml_things) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ml_things) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ml_things) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->ml_things) (1.16.0)\n","Building wheels for collected packages: ml_things\n","  Building wheel for ml_things (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ml_things: filename=ml_things-0.0.1-py3-none-any.whl size=24393 sha256=81a47e6ab62a701508581b3653a96a4beaa1e3c5d8a5ffd18b79a2cd3c579231\n","  Stored in directory: /root/.cache/pip/wheels/2a/b9/36/3725744c1d8ebec00cd847c9461b4352ce08de9d3f20b6bdcf\n","Successfully built ml_things\n","Installing collected packages: ftfy, ml_things\n","Successfully installed ftfy-6.2.0 ml_things-0.0.1\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Collecting transformers[torch]\n","  Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate\n","  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->transformers[torch])\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, accelerate\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.40.0\n","    Uninstalling transformers-4.40.0:\n","      Successfully uninstalled transformers-4.40.0\n","Successfully installed accelerate-0.29.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 transformers-4.40.1\n"]}],"source":["!pip install datasets transformers[sentencepiece] sacrebleu\n","!pip install transformers\n","!pip install ml_things\n","!pip install transformers[torch] accelerate -U"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9146,"status":"ok","timestamp":1714264814106,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"},"user_tz":240},"id":"cwpjGrCEreJj"},"outputs":[],"source":["from transformers import set_seed, AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, pipeline\n","from datasets import Dataset, load_dataset, load_metric\n","import torch\n","import pandas as pd\n","from tqdm.auto import tqdm  # tqdm is great for progress bars\n","import sacrebleu\n","import numpy as np"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":2633,"status":"ok","timestamp":1714265591898,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"},"user_tz":240},"id":"ntmlpv1Gt7ED"},"outputs":[],"source":["set_seed(42)\n","\n","dataset = load_dataset(\"csebuetnlp/BanglaNMT\")\n","# print(dataset)\n","# print(dataset['train'][0])\n","# print(dataset['train'][1])\n","# print(dataset['train'][2])\n","# print(dataset['train'][0]['bn'])\n","# print(dataset['train'][0]['en'])\n","\n","training_subset_size = 100000\n","dataset[\"train\"] = dataset[\"train\"].select(range(training_subset_size))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":387,"status":"ok","timestamp":1714265592271,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"},"user_tz":240},"id":"mAINn-p5sAn2","outputId":"600796ad-04bf-4394-d45e-48f9b5ffdbf8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]}],"source":["# Specify the model checkpoint\n","# model_checkpoint = \"facebook/nllb-200-distilled-600M\"\n","model_checkpoint = \"Helsinki-NLP/opus-mt-mul-en\"\n","# model_checkpoint = \"t5-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355,"referenced_widgets":["681c729743834abbaa6134c91fb42c2e","bd84c74609904a9cb6f9ab8c72944f8b","e84fa22e5c264ae185ee5b58d4810446","ae9128e6b27b49b7bf5db02489f3f7d7","e58e3c5b04b9440aa6f2333cd0096145","0f0a4531895c4c89a6cf9c8a208f28f5","128311c623534d749d4ee68d9a9cfec0","9ade837f1d604f718977c667a4b89010","97cfdee099f044c182263e5a98c05237","21021684093d479ea32c874b54aa5648","69ed1e5c5ff743fdbce32fb0044be172"]},"id":"WX_0b33nspN_","executionInfo":{"status":"ok","timestamp":1714265622925,"user_tz":240,"elapsed":30659,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"51bd7f90-b54d-4822-d7e1-b267cab1bd43"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"681c729743834abbaa6134c91fb42c2e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3921: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['bn', 'en', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 100000\n","    })\n","    test: Dataset({\n","        features: ['bn', 'en', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 1000\n","    })\n","    validation: Dataset({\n","        features: ['bn', 'en', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 597\n","    })\n","})\n"]}],"source":["def preprocess_function(examples):\n","    model_inputs = tokenizer(examples['bn'], max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n","    # Prepare the labels (Bengali translations)\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples['en'], max_length=128, truncation=True, padding=\"max_length\")\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenized_datasets = dataset.map(preprocess_function, batched=True)\n","print(tokenized_datasets)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"fbwOAeqityRj","executionInfo":{"status":"ok","timestamp":1714265624562,"user_tz":240,"elapsed":1654,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}}},"outputs":[],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"TWNAvwuRyTbr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714265626096,"user_tz":240,"elapsed":1536,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"6a3e77a6-424e-4fc8-88f8-3f77ae8c11b2"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/bleu/bleu.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/sacrebleu/sacrebleu.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]}],"source":["# Load both BLEU and SacreBLEU metrics\n","bleu_metric = load_metric('bleu')\n","sacrebleu_metric = load_metric('sacrebleu')\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","\n","    # In case the model returns more than the prediction logits\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds = [pred.strip() for pred in decoded_preds]\n","    decoded_labels = [[label.strip()] for label in decoded_labels]\n","\n","    # # Compute BLEU score\n","    # bleu_result = bleu_metric.compute(predictions=decoded_preds, references=[decoded_labels])\n","    # Compute SacreBLEU score\n","    sacrebleu_result = sacrebleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n","\n","    # Prepare result dictionary\n","    results = {\n","        # \"bleu\": bleu_result['score'],\n","        \"sacrebleu\": sacrebleu_result['score']\n","    }\n","\n","    return results"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"JJ5oneuGu6EL","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1714269388884,"user_tz":240,"elapsed":3762790,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"6b2bd018-53c8-46fb-f768-9360a3c07237"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Baseline Test Metrics: {'test_loss': 5.578831672668457, 'test_sacrebleu': 14.397189477569036, 'test_runtime': 59.88, 'test_samples_per_second': 16.7, 'test_steps_per_second': 1.052}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='76' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [38/38 20:01]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Baseline Validation Metrics: {'eval_loss': 5.701390266418457, 'eval_sacrebleu': 13.822322698963632, 'eval_runtime': 32.593, 'eval_samples_per_second': 18.317, 'eval_steps_per_second': 1.166}\n","\n","Fine-tuning the model...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='18750' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [18750/18750 1:01:09, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Sacrebleu</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.377400</td>\n","      <td>0.393021</td>\n","      <td>19.304227</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.318100</td>\n","      <td>0.367345</td>\n","      <td>21.111832</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.294100</td>\n","      <td>0.361596</td>\n","      <td>21.634978</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n","There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.encoder.embed_positions.weight', 'model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'lm_head.weight'].\n"]},{"output_type":"stream","name":"stdout","text":["Model fine-tuning complete.\n"]}],"source":["import logging\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","# Define the training arguments\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=3,\n","    predict_with_generate=True,\n","    logging_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"sacrebleu\",\n","    # report_to=\"none\",\n",")\n","\n","# Initialize the trainer\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","# # Pre-training test results\n","baseline_test_results = trainer.predict(tokenized_datasets[\"test\"], metric_key_prefix=\"test\")\n","print(\"Baseline Test Metrics:\", baseline_test_results.metrics)\n","baseline_validation_results = trainer.evaluate()\n","print(\"Baseline Validation Metrics:\", baseline_validation_results)\n","\n","# Fine-tune the model\n","print(\"\\nFine-tuning the model...\")\n","trainer.train()\n","print(\"Model fine-tuning complete.\")"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"0R5hFMTY-1uR","colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"status":"ok","timestamp":1714269421589,"user_tz":240,"elapsed":32722,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"077f5339-bc1c-4353-d805-290cb9aa35a2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [38/38 00:27]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Final validation Metrics {'eval_loss': 0.3615964651107788, 'eval_sacrebleu': 21.63497809691181, 'eval_runtime': 32.7573, 'eval_samples_per_second': 18.225, 'eval_steps_per_second': 1.16, 'epoch': 3.0}\n"]}],"source":["# Evaluate the model\n","validation_results = trainer.evaluate()\n","print(\"Final validation Metrics\", validation_results)"]},{"cell_type":"markdown","source":["# Test on RisingNews"],"metadata":{"id":"4GGd-UaiHVTU"}},{"cell_type":"code","execution_count":29,"metadata":{"id":"As5H8iltxwlL","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1714269476911,"user_tz":240,"elapsed":55338,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"169e29b7-e98c-4db3-8f4f-6b6518fd0096"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Final Test Metrics: {'test_loss': 0.35946884751319885, 'test_sacrebleu': 22.111349670939457, 'test_runtime': 55.3412, 'test_samples_per_second': 18.07, 'test_steps_per_second': 1.138}\n"]}],"source":["# Calculate scores on the test set\n","final_test_results = trainer.predict(tokenized_datasets[\"test\"], metric_key_prefix=\"test\")\n","print(\"Final Test Metrics:\", final_test_results.metrics)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"mn3YMpvCPE5g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714269484089,"user_tz":240,"elapsed":7193,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"8b19c3be-24b0-4ed0-88b6-21d32b193afb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sample Predictions and Labels:\n","\n","Prediction 1: The senior officials of the Bangladesh High Commissioner at the airport, Sayida Muna Tasnim, and the Bangladesh Mission in London, announced his resignation.\n","Label 1: Bangladesh High Commissioner to the United Kingdom Saida Muna Tasneen and senior officials of Bangladesh Mission in London saw him off at the airport.\n","\n","Prediction 2: Terrorism has no character, religion, and country.\n","Label 2: The terrorists have no race, religion and countries.\n","\n","Prediction 3: Drake Cabera, professor of the University of Cornelius, wrote an article called \"The Dark Side of Classed Thought.\"\n","Label 3: Derek Cabera, professor at Cornell University, wrote an essay called, \"The dark sides of categorical thinking.\"\n","\n","Prediction 4: He told the public that he would be able to buy rice oil at 45 crores per kg, rice at 50 crores, rice at 50 crores and saibin oil at 85 litres per litre.\n","Label 4: He said that people can buy onion at Tk 45 per kg, sugar at Tk 50 kg, lentil at Tk 50 kg and Soybean oil at Tk 85 per litre.\n","\n","Prediction 5: Two units of Sripur Fire Station personnel have been trying to fire for about two hours.\n","Label 5: Locals and firemen of two units of Sreepur Fire Station controlled fire with an effort of about two hours.\n","\n","Prediction 6: Prime Minister Sheikh Hasina has arrived from Rome on Thursday morning at the end of a four-day official visit to the Italian and Vatican City.\n","Label 6: Prime Minister Sheikh Hasina arrived at Abu Dhabi on Thursday morning from Rome concluding her four-day official visit to Italy and Vatican City.\n","\n","Prediction 7: Indian Prime Minister Nrendra Modi assured us that the Rohinga problem in Bangladesh will continue to continue with New Delhi.\n","Label 7: Indian Prime Minister Narendra Modi assured that New Delhi's cooperation in resolving the protracted Rohingya crisis in Bangladesh would continue.\n","\n","Prediction 8: Japan's Full Support for Bangladesh in Rohinga Rehabilitation issue\n","Label 8: Japan in full support for Bangladesh over Rohingya repatriation issue\n","\n","Prediction 9: On the night of 11 February 2012, the editor of fishranga television's message in the West Raja Bazar of the capital and the senior reporter of ATN Bangla, Runi, died peacefully at home.\n","Label 9: Sagar Sarwar, news editor of Maasranga Television, and his wife Runi, senior reporter of ATN Bangla, were brutally murdered at their rented flat in the capital's West Rajabazar on February 11, 2012.\n","\n","Prediction 10: \"Bangladesh is an outstanding example of ending religion and unity,\" he said.\n","Label 10: He said, \"Bangladesh is a clear example of inter-religion and harmony.\"\n"]}],"source":["# Decode the predictions and labels\n","decoded_predictions = tokenizer.batch_decode(final_test_results.predictions, skip_special_tokens=True)\n","decoded_labels = tokenizer.batch_decode(final_test_results.label_ids, skip_special_tokens=True)\n","\n","# Print a sample of the predictions and labels\n","print(\"Sample Predictions and Labels:\")\n","for i in range(10):  # Adjust the range to print more or fewer examples\n","    print(f\"\\nPrediction {i+1}: {decoded_predictions[i]}\")\n","    print(f\"Label {i+1}: {decoded_labels[i]}\")"]},{"cell_type":"code","source":["# Save predictions to a CSV file without column names\n","predictions_df = pd.DataFrame({'Prediction': decoded_predictions})\n","predictions_df.to_csv('results/helsinki_risingnews_predictions_mul_en.csv', index=False, header=False)\n","\n","# Save labels to a separate CSV file without column names\n","labels_df = pd.DataFrame({'Label': decoded_labels})\n","labels_df.to_csv('results/helsinki_risingnews_labels_mul_en.csv', index=False, header=False)"],"metadata":{"id":"PTB6yYW0HZVK","executionInfo":{"status":"ok","timestamp":1714269484089,"user_tz":240,"elapsed":17,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TZNwF-RXzap0"},"source":["# Test on SUPara-benchmark"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Lrat8izRzgOj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714269484089,"user_tz":240,"elapsed":16,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"cc433d67-c124-4808-e9f0-d9abccb60e99"},"outputs":[{"output_type":"stream","name":"stdout","text":["সে লাল গোলাপ পছন্দ করে।\n","\n","She likes red roses.\n","\n"]}],"source":["supara_source_test_path = f\"hasan-etal-2020-low/data/SUPara-benchmark/suparatest2018/suparatest2018_bn.txt\"\n","supara_target_test_path = f\"hasan-etal-2020-low/data/SUPara-benchmark/suparatest2018/suparatest2018_en.txt\"\n","\n","with open(supara_source_test_path, \"r\", encoding=\"utf-8\") as f:\n","    supara_source_data = f.readlines()\n","\n","with open(supara_target_test_path, \"r\", encoding=\"utf-8\") as f:\n","    supara_target_data = f.readlines()\n","\n","print(supara_source_data[0])\n","print(supara_target_data[0])"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"72spdWKmzqt5","colab":{"base_uri":"https://localhost:8080/","height":176,"referenced_widgets":["2e06eef6e0cc4539a3f837e9f57c4341","3a38810b8d104fc393691c4d4e4970b5","98097235473b45d6a070a15a75037683","bd429f5636194d97a03be2dd6cb66116","a9c218e8219c4ef8a149e6e974f18629","250c4255976d45e0b44ff281d26396f0","c5669ab3336249488ef14c7ffa937116","8f4ca94bf0f847b99b3a25e7216e6e48","46040f67beae4ffc8e028a0de7ae55be","69c7c335f98a4c80bcc36b84ed60da35","0ed980f28f0c42b482d3c06afbe60c75"]},"executionInfo":{"status":"ok","timestamp":1714269484915,"user_tz":240,"elapsed":841,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"a9f8221a-d2b5-47c1-b65a-5a1d00fcae8e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e06eef6e0cc4539a3f837e9f57c4341"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['bn', 'en', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 500\n","})\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3921: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}],"source":["supara_dataset = Dataset.from_dict({\"bn\": supara_source_data, \"en\": supara_target_data})\n","tokenized_supara_dataset = supara_dataset.map(preprocess_function, batched=True)\n","print(tokenized_supara_dataset)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"lnD0ZWLQzyv8","colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"ok","timestamp":1714269508699,"user_tz":240,"elapsed":23788,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"f7fe296d-b053-43b9-b5c9-4986b27be5c6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Final test metrics SUPara: {'test_loss': 0.42624175548553467, 'test_sacrebleu': 18.777902899595272, 'test_runtime': 23.7257, 'test_samples_per_second': 21.074, 'test_steps_per_second': 1.349}\n","Final test results SUPara: PredictionOutput(predictions=array([[64171,   893,   345, ..., 64171, 64171, 64171],\n","       [64171,   220,  4632, ..., 64171, 64171, 64171],\n","       [64171,   170,  1264, ..., 64171, 64171, 64171],\n","       ...,\n","       [64171,  1596,    88, ..., 64171, 64171, 64171],\n","       [64171,    51,  4842, ..., 64171, 64171, 64171],\n","       [64171,  3695,   369, ..., 64171, 64171, 64171]]), label_ids=array([[  893,   345,     6, ..., 64171, 64171, 64171],\n","       [  220,  2582,   130, ..., 64171, 64171, 64171],\n","       [  170,  1264,    11, ..., 64171, 64171, 64171],\n","       ...,\n","       [ 5893, 10767,     5, ..., 64171, 64171, 64171],\n","       [   51, 18406,   773, ..., 64171, 64171, 64171],\n","       [ 3695,   369, 12048, ..., 64171, 64171, 64171]]), metrics={'test_loss': 0.42624175548553467, 'test_sacrebleu': 18.777902899595272, 'test_runtime': 23.7257, 'test_samples_per_second': 21.074, 'test_steps_per_second': 1.349})\n"]}],"source":["final_test_results_supara = trainer.predict(tokenized_supara_dataset, metric_key_prefix=\"test\")\n","print(\"Final test metrics SUPara:\", final_test_results_supara.metrics)\n","print(\"Final test results SUPara:\", final_test_results_supara)"]},{"cell_type":"code","source":["# Decode the predicted sequences\n","decoded_predictions_supara = tokenizer.batch_decode(final_test_results_supara.predictions, skip_special_tokens=True)\n","labels_supara = np.where(final_test_results_supara.label_ids != -100, final_test_results_supara.label_ids, tokenizer.pad_token_id)\n","decoded_labels_supara = tokenizer.batch_decode(labels_supara, skip_special_tokens=True)\n","\n","# Print a sample of the predictions and labels\n","print(\"Sample Predictions and Labels:\")\n","for i in range(10):  # Adjust the range to print more or fewer examples\n","    print(f\"\\nPrediction {i+1}: {decoded_predictions_supara[i]}\")\n","    print(f\"Label {i+1}: {decoded_labels_supara[i]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLg4aQPxH8DW","executionInfo":{"status":"ok","timestamp":1714269512107,"user_tz":240,"elapsed":3422,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}},"outputId":"4e24979d-ffb5-4311-a15b-0aef0171d609"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample Predictions and Labels:\n","\n","Prediction 1: She likes red golf.\n","Label 1: She likes red roses.\n","\n","Prediction 2: It strengthens our body.\n","Label 2: It makes our body firm.\n","\n","Prediction 3: We live in Bangladesh.\n","Label 3: We live in Bangladesh.\n","\n","Prediction 4: Human life is too short.\n","Label 4: Human life is very short.\n","\n","Prediction 5: Traffic police have many responsibilities.\n","Label 5: Traffic police have heavy responsibilities.\n","\n","Prediction 6: Cricket is my favorite game.\n","Label 6: Cricket is my favourite game.\n","\n","Prediction 7: People should be careful.\n","Label 7: Mass awareness should be created.\n","\n","Prediction 8: There may be some problems.\n","Label 8: There may be some difficulties.\n","\n","Prediction 9: What's her name?\n","Label 9: What is her name?\n","\n","Prediction 10: Our college is very old.\n","Label 10: Our college is very ancient.\n"]}]},{"cell_type":"code","source":["# Save predictions to a CSV file without column names\n","predictions_df = pd.DataFrame({'Prediction': decoded_predictions_supara})\n","predictions_df.to_csv('results/helsinki_supara_predictions_mul_en.csv', index=False, header=False)\n","\n","# Save labels to a separate CSV file without column names\n","labels_df = pd.DataFrame({'Label': decoded_labels_supara})\n","labels_df.to_csv('results/helsinki_supara_labels_mul_en.csv', index=False, header=False)"],"metadata":{"id":"es0lwakmHwnG","executionInfo":{"status":"ok","timestamp":1714269512293,"user_tz":240,"elapsed":201,"user":{"displayName":"Jason Sun","userId":"05795037598047629343"}}},"execution_count":36,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"681c729743834abbaa6134c91fb42c2e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd84c74609904a9cb6f9ab8c72944f8b","IPY_MODEL_e84fa22e5c264ae185ee5b58d4810446","IPY_MODEL_ae9128e6b27b49b7bf5db02489f3f7d7"],"layout":"IPY_MODEL_e58e3c5b04b9440aa6f2333cd0096145"}},"bd84c74609904a9cb6f9ab8c72944f8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f0a4531895c4c89a6cf9c8a208f28f5","placeholder":"​","style":"IPY_MODEL_128311c623534d749d4ee68d9a9cfec0","value":"Map: 100%"}},"e84fa22e5c264ae185ee5b58d4810446":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ade837f1d604f718977c667a4b89010","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_97cfdee099f044c182263e5a98c05237","value":100000}},"ae9128e6b27b49b7bf5db02489f3f7d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21021684093d479ea32c874b54aa5648","placeholder":"​","style":"IPY_MODEL_69ed1e5c5ff743fdbce32fb0044be172","value":" 100000/100000 [00:28&lt;00:00, 2787.33 examples/s]"}},"e58e3c5b04b9440aa6f2333cd0096145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f0a4531895c4c89a6cf9c8a208f28f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"128311c623534d749d4ee68d9a9cfec0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ade837f1d604f718977c667a4b89010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97cfdee099f044c182263e5a98c05237":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21021684093d479ea32c874b54aa5648":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69ed1e5c5ff743fdbce32fb0044be172":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e06eef6e0cc4539a3f837e9f57c4341":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a38810b8d104fc393691c4d4e4970b5","IPY_MODEL_98097235473b45d6a070a15a75037683","IPY_MODEL_bd429f5636194d97a03be2dd6cb66116"],"layout":"IPY_MODEL_a9c218e8219c4ef8a149e6e974f18629"}},"3a38810b8d104fc393691c4d4e4970b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_250c4255976d45e0b44ff281d26396f0","placeholder":"​","style":"IPY_MODEL_c5669ab3336249488ef14c7ffa937116","value":"Map: 100%"}},"98097235473b45d6a070a15a75037683":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f4ca94bf0f847b99b3a25e7216e6e48","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46040f67beae4ffc8e028a0de7ae55be","value":500}},"bd429f5636194d97a03be2dd6cb66116":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69c7c335f98a4c80bcc36b84ed60da35","placeholder":"​","style":"IPY_MODEL_0ed980f28f0c42b482d3c06afbe60c75","value":" 500/500 [00:00&lt;00:00, 2563.86 examples/s]"}},"a9c218e8219c4ef8a149e6e974f18629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"250c4255976d45e0b44ff281d26396f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5669ab3336249488ef14c7ffa937116":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f4ca94bf0f847b99b3a25e7216e6e48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46040f67beae4ffc8e028a0de7ae55be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69c7c335f98a4c80bcc36b84ed60da35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ed980f28f0c42b482d3c06afbe60c75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}